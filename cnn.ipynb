{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "QdXbfRyIgv9K",
    "outputId": "bad419f8-4142-45be-d5cd-7b13744a3ef5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "id": "tW4yd9pgI8K9",
    "outputId": "21563e2b-7bd2-4c65-87f7-f4bd4a28fe0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorboardcolab\n",
    "from tensorboardcolab import TensorBoardColab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9V06lJ3ahEjm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aLEnkF2Da1OZ"
   },
   "source": [
    "## Using GPU for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ft1gp5ku53f"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aoBNPF4sa5RB"
   },
   "source": [
    "## Mapping class names to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dIm2XxaSZazv"
   },
   "outputs": [],
   "source": [
    "mappings1 = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "mappings2 = {mapping: i for i, mapping in enumerate(mappings1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OHfzm-jIa9yq"
   },
   "source": [
    "## Defining Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhXzbaIenZTI"
   },
   "outputs": [],
   "source": [
    "class CINIC(Dataset):\n",
    "  def __init__(self, root_dir, transform=None):\n",
    "    path = Path(root_dir)\n",
    "    self.img_list = []\n",
    "    self.label_list = []\n",
    "    self.transform = transform\n",
    "    for filename in path.rglob('*.png'):\n",
    "      self.img_list.append(filename)\n",
    "      self.label_list.append(mappings2[str(filename).split('/')[-2]])\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.label_list)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    img_file, label = self.img_list[idx], self.label_list[idx]\n",
    "    img = PIL.Image.open(self.img_list[idx]).convert('RGB')\n",
    "    if self.transform:\n",
    "      img = self.transform(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YbSyDReMbCpz"
   },
   "source": [
    "## Defining batch parameters and normalization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RH5XbpbN5ByX"
   },
   "outputs": [],
   "source": [
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 4}\n",
    "\n",
    "data_mean = [0.47889522, 0.47227842, 0.43047404]\n",
    "data_std = [0.24205776, 0.23828046, 0.25874835]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "teoUKM6bbJNf"
   },
   "source": [
    "## Defining transforms for all 3 sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ysPycVFAjNj"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([  \n",
    "    transforms.RandomResizedCrop(32),                               \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=data_mean, std=data_std)\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=data_mean, std=data_std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=data_mean, std=data_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TzaglrbDbOWx"
   },
   "source": [
    "## Utilizing Dataloader class to read data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f6fnuhva4SLQ"
   },
   "outputs": [],
   "source": [
    "train_set = CINIC(root_dir='data/CINIC-10/train/', transform=train_transform)\n",
    "train_generator = data.DataLoader(train_set, **params)\n",
    "\n",
    "val_set = CINIC(root_dir='data/CINIC-10/valid/', transform=val_transform)\n",
    "val_generator = data.DataLoader(val_set, **params)\n",
    "\n",
    "test_set = CINIC(root_dir='data/CINIC-10/test/', transform=test_transform)\n",
    "test_generator = data.DataLoader(test_set, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dwpvi2tVbSi7"
   },
   "source": [
    "## Creating the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "_csIwq0OOWJE",
    "outputId": "7e154601-0313-45dd-9531-6ad56e325ad4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv1_bn): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc1_bn): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc2_bn): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv2_bn = nn.BatchNorm2d(16)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc1_bn = nn.BatchNorm1d(120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc2_bn = nn.BatchNorm1d(84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1_bn(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.conv2_bn(self.conv2(x))))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eR-kD7X1bV4N"
   },
   "source": [
    "## Defining loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hqqemeS2OVim"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3FsMHkJ7bbt-"
   },
   "source": [
    "## Defining tensorboard object to visualize train and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "RLj_d9ZRRoQh",
    "outputId": "59d2cb64-73c3-4522-e695-514c36d5beb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait for 8 seconds...\n",
      "TensorBoard link:\n",
      "https://3ba17921.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "tb = TensorBoardColab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "6oRyP9yNOVdJ",
    "outputId": "9379055b-456f-481b-ed3f-e2ccc1b0a8f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, validation loss: 1.4255568037324537\n",
      "epoch 2, validation loss: 1.3582773215396233\n",
      "epoch 3, validation loss: 1.3171266990938166\n",
      "epoch 4, validation loss: 1.2540081053993426\n",
      "epoch 5, validation loss: 1.2697775596070984\n",
      "epoch 6, validation loss: 1.2250465550317609\n",
      "epoch 7, validation loss: 1.2156548625455312\n",
      "epoch 8, validation loss: 1.221214744497379\n",
      "epoch 9, validation loss: 1.2174939858464375\n",
      "epoch 10, validation loss: 1.20006222375844\n",
      "epoch 11, validation loss: 1.1969650040811568\n",
      "epoch 12, validation loss: 1.2072135312555525\n",
      "epoch 13, validation loss: 1.1933394203646943\n",
      "epoch 14, validation loss: 1.193514760877532\n",
      "epoch 15, validation loss: 1.1923298025775142\n",
      "epoch 16, validation loss: 1.1891987467794953\n",
      "epoch 17, validation loss: 1.1778091615027542\n",
      "epoch 18, validation loss: 1.1897228596137615\n",
      "epoch 19, validation loss: 1.1795961424740138\n",
      "epoch 20, validation loss: 1.1809912317597282\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for epoch in range(20):\n",
    "\n",
    "  val_running_loss = 0\n",
    "  net.train()\n",
    "  for i, dat in enumerate(train_generator):\n",
    "    j += 1\n",
    "    # get image, label pair\n",
    "    inputs, labels = dat\n",
    "\n",
    "    #using GPU\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # set parameter gradients to 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward pass for a batch\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Backpropagate\n",
    "    loss.backward()\n",
    "\n",
    "    # update the weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # print training loss\n",
    "    #print('[{}, {}] training loss:{}'.format(epoch+1, i+1, loss.item()))\n",
    "    tb.save_value('Train Loss', 'train_loss', j, loss.item())\n",
    "\n",
    "  net.eval()\n",
    "  with torch.no_grad():\n",
    "    for k, dat1 in enumerate(val_generator):\n",
    "      inputs1, labels1 = dat1\n",
    "      inputs1 = inputs1.to(device)\n",
    "      labels1 = labels1.to(device)\n",
    "      outputs1 = net(inputs1)\n",
    "      loss1 = criterion(outputs1, labels1)\n",
    "      val_running_loss += loss1\n",
    "\n",
    "    avg_val_loss = float(val_running_loss)/(k+1)\n",
    "    print('epoch {}, validation loss: {}'.format(epoch+1, avg_val_loss))\n",
    "    tb.save_value('Validation Loss', 'val_loss', epoch+1, avg_val_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0aWj3LPbHun"
   },
   "source": [
    "## Overall test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XeVQIQiFwxZR",
    "outputId": "6ca3b8d9-040d-4b77-e55c-0fdb1b4f9cf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 57.83555555555556%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "  for data in test_generator:\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Test set accuracy = {}%'.format(100.0 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3Tz9Gt-bGym"
   },
   "source": [
    "## Class by class test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_wAwgBhLd3MM"
   },
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in test_generator:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "Zt9WZlJagJmQ",
    "outputId": "12f4ed3b-f202-442f-b06b-0464ecf8b62a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of airplane: 70.45%\n",
      "Accuracy of automobile: 60.63%\n",
      "Accuracy of bird: 47.37%\n",
      "Accuracy of cat: 44.09%\n",
      "Accuracy of deer: 51.06%\n",
      "Accuracy of dog: 39.51%\n",
      "Accuracy of frog: 64.85%\n",
      "Accuracy of horse: 66.14%\n",
      "Accuracy of ship: 67.88%\n",
      "Accuracy of truck: 60.77%\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  print('Accuracy of {}: {}%'.format(mappings1[i], round(100 * class_correct[i] / class_total[i], 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BN1Eob-KRELJ"
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "yUbh5AX5RDal",
    "outputId": "34adea35-31e7-4226-cf91-89644c584249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6299.,  243.,  470.,  109.,  159.,  136.,   43.,  222., 1000.,  319.],\n",
      "        [ 311., 5796.,  112.,  148.,  130.,  184.,   66.,  164.,  641., 1448.],\n",
      "        [ 588.,   57., 4270.,  904., 1023.,  763.,  655.,  313.,  371.,   56.],\n",
      "        [ 136.,   71.,  600., 3955., 1011., 1829.,  713.,  360.,  218.,  107.],\n",
      "        [ 215.,   62.,  560.,  900., 4670.,  880.,  313., 1080.,  235.,   85.],\n",
      "        [ 142.,  105.,  603., 1724., 1180., 3794.,  299.,  811.,  215.,  127.],\n",
      "        [  60.,   54.,  579., 1191.,  484.,  446., 5992.,   67.,  100.,   27.],\n",
      "        [ 146.,   82.,  242.,  433.,  964.,  879.,   50., 5886.,  147.,  171.],\n",
      "        [ 948.,  350.,  336.,  279.,  213.,  178.,   81.,  166., 5989.,  460.],\n",
      "        [ 360., 1606.,   89.,  180.,  148.,  170.,   43.,  293.,  710., 5401.]])\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = torch.zeros(10, 10)\n",
    "with torch.no_grad():\n",
    "  for data in test_generator:\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
    "      confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_TdplKNLiAja"
   },
   "outputs": [],
   "source": [
    "# !mkdir /content/data\n",
    "# !cp /content/drive/My\\ Drive/csci_677_hw4/CINIC-10.tar.gz /content/data\n",
    "# !mkdir /content/data/CINIC-10\n",
    "# !tar -xvzf /content/data/CINIC-10.tar.gz -C /content/data/CINIC-10"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
